{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a7036e",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and FAISS \n",
    "Introduction to RAG (Retrieval-Augmented Generation)\n",
    "RAG combines the power of retrieval systems with generative AI models. Instead of relying solely on the model's training data, RAG:\n",
    "\n",
    "1. Retrieves relevant documents from a knowledge base\n",
    "2. Uses these documents as context for the LLM\n",
    "3. Generates responses based on both the retrieved context and the model's knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937ab9f",
   "metadata": {},
   "source": [
    "### FAISS \n",
    "https://github.com/facebookresearch/faiss\n",
    "\n",
    "FAISS is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "Key advantages:\n",
    "1. Extremely fast similarity search\n",
    "2. Memory efficient\n",
    "3. Supports GPU acceleration\n",
    "4. Can handle millions of vectors\n",
    "\n",
    "How it works:\n",
    "- Indexes vectors for fast nearest neighbor search\n",
    "- Returns most similar vectors based on distance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dae1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0af024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain core imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough, \n",
    " \n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# LangChain specific imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "#from langchain.chains import create_retrieval_chain\n",
    "#from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4adfdc",
   "metadata": {},
   "source": [
    "### Data Ingestion And Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511190a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='\\n        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.\\n        '), Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='\\n        Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.\\n        '), Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='\\n        Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.\\n        '), Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='\\n        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.\\n        ')]\n"
     ]
    }
   ],
   "source": [
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
    "        These systems are designed to think like humans and mimic their actions.\n",
    "        AI can be categorized into narrow AI and general AI.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"AI Introduction\", \"page\": 1, \"topic\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Machine Learning is a subset of AI that enables systems to learn from data.\n",
    "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
    "        Common types include supervised, unsupervised, and reinforcement learning.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"ML Basics\", \"page\": 1, \"topic\": \"ML\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Deep Learning is a subset of machine learning based on artificial neural networks.\n",
    "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
    "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"Deep Learning\", \"page\": 1, \"topic\": \"DL\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
    "        It combines computational linguistics with machine learning and deep learning models.\n",
    "        Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"NLP Overview\", \"page\": 1, \"topic\": \"NLP\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(sample_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028d3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
      "        These systems are designed to think like humans and mimic their actions.\n",
      "        AI can be categorized into narrow AI and general AI.' metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}\n",
      "page_content='Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised, unsupervised, and reinforcement learning.' metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}\n"
     ]
    }
   ],
   "source": [
    "## text splitting\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "\n",
    "## split the documents into chunks\n",
    "chunks = text_splitter.split_documents(sample_documents)\n",
    "print(chunks[0])\n",
    "print(chunks[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed228b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 chunks from 4 documents\n",
      "\n",
      "Example chunk:\n",
      "Content: Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
      "        These systems are designed to think like humans and mimic their actions.\n",
      "        AI can be categorized into narrow AI and general AI.\n",
      "Metadata: {'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(sample_documents)} documents\")\n",
    "print(\"\\nExample chunk:\")\n",
    "print(f\"Content: {chunks[0].page_content}\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1051ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the embedding models\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab0c2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.029035670682787895,\n",
       " 0.007559708319604397,\n",
       " 0.04076479375362396,\n",
       " 0.030535506084561348,\n",
       " 0.051757071167230606,\n",
       " -0.017347579821944237,\n",
       " -0.0309417936950922,\n",
       " -0.065562903881073,\n",
       " -0.03306080028414726,\n",
       " -0.009561269544064999,\n",
       " -0.09131377935409546,\n",
       " 0.04738364741206169,\n",
       " 0.02773960493505001,\n",
       " -0.06366031616926193,\n",
       " -0.06504752486944199,\n",
       " 0.04200266674160957,\n",
       " -0.0402190126478672,\n",
       " 0.028005117550492287,\n",
       " -0.028049876913428307,\n",
       " -0.053762856870889664,\n",
       " -0.005428337026387453,\n",
       " 0.006084765773266554,\n",
       " -0.07086586207151413,\n",
       " 0.025930076837539673,\n",
       " 0.010079472325742245,\n",
       " 0.026293443515896797,\n",
       " 0.038574572652578354,\n",
       " 0.022752394899725914,\n",
       " -0.01670047827064991,\n",
       " 0.009418012574315071,\n",
       " 0.016376066952943802,\n",
       " -0.05924323946237564,\n",
       " -0.01635240577161312,\n",
       " 0.04579908400774002,\n",
       " -0.06120175123214722,\n",
       " 0.061170995235443115,\n",
       " -0.013366843573749065,\n",
       " -0.0003110978286713362,\n",
       " 0.03935335949063301,\n",
       " -0.04183920845389366,\n",
       " -0.03927678242325783,\n",
       " -0.10107354074716568,\n",
       " -0.006085092667490244,\n",
       " -0.011100538074970245,\n",
       " 0.12034154683351517,\n",
       " 0.10397820919752121,\n",
       " -0.05519598349928856,\n",
       " -0.11298872530460358,\n",
       " -0.032693829387426376,\n",
       " 0.014702783897519112,\n",
       " -0.09101349860429764,\n",
       " -0.038357239216566086,\n",
       " 0.0027517240960150957,\n",
       " -0.008734755218029022,\n",
       " -0.05779308080673218,\n",
       " 0.033151593059301376,\n",
       " 0.05066526681184769,\n",
       " -0.009161509573459625,\n",
       " 0.00198278296738863,\n",
       " -0.011107906699180603,\n",
       " 0.015205725096166134,\n",
       " -0.1520676165819168,\n",
       " -0.024107489734888077,\n",
       " 0.03700369969010353,\n",
       " 0.06354302167892456,\n",
       " -0.0272714514285326,\n",
       " -0.03705175966024399,\n",
       " 0.014332616701722145,\n",
       " 0.007579052355140448,\n",
       " -0.09305106848478317,\n",
       " -0.010146296583116055,\n",
       " 0.04867212101817131,\n",
       " 0.010806962847709656,\n",
       " 0.07799933105707169,\n",
       " 0.03921523690223694,\n",
       " 0.008822093717753887,\n",
       " 0.0032744258642196655,\n",
       " -0.02666976861655712,\n",
       " 0.09167905151844025,\n",
       " 0.06515678018331528,\n",
       " -0.012353220954537392,\n",
       " 0.018279388546943665,\n",
       " -0.044020626693964005,\n",
       " 0.08364027738571167,\n",
       " 0.06395307183265686,\n",
       " -0.05506033077836037,\n",
       " -0.05808797851204872,\n",
       " -0.0018746948335319757,\n",
       " -0.04740576073527336,\n",
       " -0.027536293491721153,\n",
       " -0.02880473993718624,\n",
       " -0.027462724596261978,\n",
       " -0.021264029666781425,\n",
       " -0.018902122974395752,\n",
       " -0.06173022463917732,\n",
       " 0.027876464650034904,\n",
       " -0.025475677102804184,\n",
       " -0.10327435284852982,\n",
       " 0.006333625875413418,\n",
       " 0.07414139807224274,\n",
       " -0.05245545879006386,\n",
       " 0.08629944920539856,\n",
       " 0.012340142391622066,\n",
       " -0.02364432066679001,\n",
       " 0.06663603335618973,\n",
       " -0.013113793917000294,\n",
       " 0.014714349061250687,\n",
       " -0.023595931008458138,\n",
       " 0.09515439718961716,\n",
       " -0.11606636643409729,\n",
       " -0.06480208039283752,\n",
       " 0.028634214773774147,\n",
       " -0.0315549410879612,\n",
       " -0.041730161756277084,\n",
       " -0.03608325496315956,\n",
       " -0.006182955112308264,\n",
       " -0.03813052922487259,\n",
       " 0.004320627544075251,\n",
       " -0.03699594363570213,\n",
       " 0.06302621960639954,\n",
       " -0.06653684377670288,\n",
       " 6.59498036839068e-05,\n",
       " 0.004346208181232214,\n",
       " 0.025370901450514793,\n",
       " 0.026382748037576675,\n",
       " -0.0990355834364891,\n",
       " -0.07831867784261703,\n",
       " -6.010210780258198e-33,\n",
       " 0.024687625467777252,\n",
       " -0.10524407774209976,\n",
       " 0.0009759414824657142,\n",
       " -0.023231692612171173,\n",
       " 0.04899437725543976,\n",
       " -0.10262829810380936,\n",
       " -0.03501954302191734,\n",
       " -0.06349784135818481,\n",
       " 0.029802994802594185,\n",
       " 0.03785918653011322,\n",
       " -0.029759736731648445,\n",
       " 0.007283484097570181,\n",
       " 0.037147946655750275,\n",
       " 0.06798265129327774,\n",
       " 0.06864472478628159,\n",
       " 0.026472270488739014,\n",
       " -0.007139091845601797,\n",
       " 0.04937395080924034,\n",
       " 0.01627492904663086,\n",
       " -0.04618831351399422,\n",
       " 0.038982000201940536,\n",
       " 0.008404073305428028,\n",
       " 0.029958751052618027,\n",
       " 0.021006735041737556,\n",
       " -0.03257215395569801,\n",
       " 0.06217190995812416,\n",
       " 0.029418881982564926,\n",
       " 0.0748555064201355,\n",
       " 0.043728310614824295,\n",
       " 0.03351590037345886,\n",
       " 0.013613251969218254,\n",
       " 0.01398500893265009,\n",
       " -0.053614292293787,\n",
       " 0.003676444059237838,\n",
       " 0.04363549128174782,\n",
       " -0.010907864198088646,\n",
       " -0.003753600176423788,\n",
       " -0.004634873941540718,\n",
       " 0.04214829206466675,\n",
       " 0.028949469327926636,\n",
       " 0.008460797369480133,\n",
       " -0.045049551874399185,\n",
       " 0.0733589380979538,\n",
       " -0.07362175732851028,\n",
       " -0.07764668762683868,\n",
       " 0.05312054231762886,\n",
       " 0.01565726101398468,\n",
       " -0.10681517422199249,\n",
       " -0.0790257602930069,\n",
       " -0.04125157743692398,\n",
       " -0.0289156474173069,\n",
       " -0.06834135204553604,\n",
       " -0.03997884690761566,\n",
       " 0.0062007722444832325,\n",
       " 0.022057225927710533,\n",
       " 0.10797026008367538,\n",
       " -0.0024693948216736317,\n",
       " -0.0034637623466551304,\n",
       " -0.05418191850185394,\n",
       " -0.005846276879310608,\n",
       " 0.05413012579083443,\n",
       " 0.052959322929382324,\n",
       " 0.020870326086878777,\n",
       " 0.0789758488535881,\n",
       " -0.010170389898121357,\n",
       " 0.015605548396706581,\n",
       " 0.08540286123752594,\n",
       " 0.04105133190751076,\n",
       " 0.08442144840955734,\n",
       " -0.009051019325852394,\n",
       " 0.043454360216856,\n",
       " 0.007145559415221214,\n",
       " 0.025493383407592773,\n",
       " -0.03796227648854256,\n",
       " 0.061059992760419846,\n",
       " -0.01141707506030798,\n",
       " 0.05236940458416939,\n",
       " 0.040447674691677094,\n",
       " -0.01963658817112446,\n",
       " 0.05107366293668747,\n",
       " -0.022881822660565376,\n",
       " -0.03634713590145111,\n",
       " -0.003598571987822652,\n",
       " -0.07658213376998901,\n",
       " -0.013934827409684658,\n",
       " 0.056446369737386703,\n",
       " -0.02765151672065258,\n",
       " -0.03730526193976402,\n",
       " -0.03187882900238037,\n",
       " 0.015561698004603386,\n",
       " -0.12173198908567429,\n",
       " 0.0073179942555725574,\n",
       " 0.011212223209440708,\n",
       " 0.019803782925009727,\n",
       " -0.06352611631155014,\n",
       " 2.327825034448645e-33,\n",
       " -0.06423308700323105,\n",
       " 0.009110324084758759,\n",
       " -0.013949161395430565,\n",
       " 0.09450729191303253,\n",
       " 0.030099686235189438,\n",
       " 0.014080916531383991,\n",
       " -0.07846364378929138,\n",
       " 0.032595690339803696,\n",
       " -0.08949309587478638,\n",
       " 0.06275837868452072,\n",
       " 0.016260841861367226,\n",
       " -0.021571576595306396,\n",
       " 0.08164018392562866,\n",
       " 0.03085722029209137,\n",
       " -0.004192194901406765,\n",
       " 0.05958322808146477,\n",
       " -0.07337909936904907,\n",
       " -0.01143137738108635,\n",
       " -0.035104043781757355,\n",
       " 0.048267751932144165,\n",
       " -0.01787303201854229,\n",
       " 0.060254909098148346,\n",
       " 0.022646693512797356,\n",
       " -0.016905661672353745,\n",
       " 0.04184363782405853,\n",
       " -0.01720411702990532,\n",
       " -0.037558771669864655,\n",
       " 0.025142375379800797,\n",
       " -0.025869520381093025,\n",
       " 0.028740402311086655,\n",
       " 0.0022359758149832487,\n",
       " 0.025622934103012085,\n",
       " -0.036963365972042084,\n",
       " 0.006590997334569693,\n",
       " 0.05629263073205948,\n",
       " 0.016468970105051994,\n",
       " 0.028691373765468597,\n",
       " -0.05175890773534775,\n",
       " 0.03845475614070892,\n",
       " 0.09314846247434616,\n",
       " -0.006300178822129965,\n",
       " 0.018203159794211388,\n",
       " -0.07134727388620377,\n",
       " -0.08328655362129211,\n",
       " -0.0335078090429306,\n",
       " -0.013967175036668777,\n",
       " -0.010001459158957005,\n",
       " -0.0186599213629961,\n",
       " 0.06312134116888046,\n",
       " -0.08709115535020828,\n",
       " 0.021946951746940613,\n",
       " 0.0911896824836731,\n",
       " 0.021971851587295532,\n",
       " -0.05642063170671463,\n",
       " -0.023548126220703125,\n",
       " 0.04782738909125328,\n",
       " -0.04286780208349228,\n",
       " 0.015484868548810482,\n",
       " 0.00933241005986929,\n",
       " 0.10468806326389313,\n",
       " -0.06996076554059982,\n",
       " -0.04021305963397026,\n",
       " 0.04386873170733452,\n",
       " -0.02581094391644001,\n",
       " 0.0043016355484724045,\n",
       " 0.07126873731613159,\n",
       " 0.010412923991680145,\n",
       " 0.06600604951381683,\n",
       " -0.025652777403593063,\n",
       " 0.005441861692816019,\n",
       " 0.03430502116680145,\n",
       " 0.08808634430170059,\n",
       " -0.0045437938533723354,\n",
       " 0.09099522233009338,\n",
       " -0.048365090042352676,\n",
       " -0.08146054297685623,\n",
       " -0.02073209546506405,\n",
       " -0.05615420266985893,\n",
       " -0.05486655980348587,\n",
       " -0.010379781946539879,\n",
       " 0.03315393999218941,\n",
       " -0.11480744928121567,\n",
       " 0.01881616748869419,\n",
       " 0.06738898158073425,\n",
       " -0.00207202578894794,\n",
       " -0.049707118421792984,\n",
       " 0.0061363945715129375,\n",
       " 0.0219399556517601,\n",
       " -0.04654258117079735,\n",
       " -0.07037464529275894,\n",
       " -0.04876377433538437,\n",
       " 0.03741269186139107,\n",
       " -0.06766542792320251,\n",
       " 0.07526884227991104,\n",
       " -0.10176165401935577,\n",
       " -1.3521183284126437e-08,\n",
       " -0.007577857933938503,\n",
       " -0.02333793416619301,\n",
       " 0.09829691052436829,\n",
       " -0.08803719282150269,\n",
       " 0.08125018328428268,\n",
       " 0.05348080024123192,\n",
       " -0.0777851790189743,\n",
       " 0.09395745396614075,\n",
       " -0.04696726053953171,\n",
       " -0.04920148849487305,\n",
       " 0.033225055783987045,\n",
       " 0.04946211352944374,\n",
       " -0.0318148136138916,\n",
       " 0.022869756445288658,\n",
       " -0.042323172092437744,\n",
       " 0.00940761435776949,\n",
       " 0.02744472026824951,\n",
       " 0.02607029676437378,\n",
       " 0.009801066480576992,\n",
       " 0.08153564482927322,\n",
       " 0.11052554100751877,\n",
       " -0.030864691361784935,\n",
       " 0.03337625041604042,\n",
       " -0.05804485082626343,\n",
       " 0.11017011851072311,\n",
       " -0.13507068157196045,\n",
       " -0.004004037007689476,\n",
       " 0.05443384498357773,\n",
       " -0.006387476343661547,\n",
       " 0.004196984693408012,\n",
       " -0.07071344554424286,\n",
       " 0.08257731795310974,\n",
       " 0.022407233715057373,\n",
       " -0.015863152220845222,\n",
       " 0.02466166391968727,\n",
       " 0.06775176525115967,\n",
       " 0.0565558560192585,\n",
       " -0.10201206058263779,\n",
       " -0.07249483466148376,\n",
       " -0.003024908946827054,\n",
       " -0.031181255355477333,\n",
       " 0.1169450655579567,\n",
       " -0.057320043444633484,\n",
       " 0.02268254943192005,\n",
       " -0.02275138534605503,\n",
       " 0.06624628603458405,\n",
       " 0.08006953448057175,\n",
       " -0.06961195915937424,\n",
       " -0.046753253787755966,\n",
       " 0.014536743983626366,\n",
       " 0.017521629109978676,\n",
       " 0.05432004854083061,\n",
       " 0.055380940437316895,\n",
       " 0.07079683989286423,\n",
       " 0.043306637555360794,\n",
       " 0.02344869077205658,\n",
       " 0.017352553084492683,\n",
       " -0.07405108958482742,\n",
       " 0.021884864196181297,\n",
       " 0.03273167833685875,\n",
       " 0.001552832080051303,\n",
       " 0.03983815759420395,\n",
       " 0.05342578515410423,\n",
       " -0.03610841557383537]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize OpenAI embeddings with the latest model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#embeddings=OpenAIEmbeddings(\n",
    "#    model=\"text-embedding-3-small\",\n",
    "#    dimensions=1536\n",
    "#)\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "## Example: create a embedding for a single text\n",
    "sample_text=\"What is machine learning\"\n",
    "sample_embedding=embeddings.embed_query(sample_text)\n",
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476c19c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03653926029801369, -0.01516436506062746, 0.016432488337159157, 0.010568845085799694, 0.00601056357845664, -0.01847330667078495, 0.08546523749828339, 0.02096840925514698, 0.02781531773507595, 0.012431666254997253, -0.02937646210193634, -0.03113521821796894, 0.03491252660751343, -0.018150832504034042, -0.06498479098081589, 0.0516824945807457, -0.019606243818998337, -0.015734165906906128, -0.13371673226356506, -0.09645991772413254, -0.02547178417444229, -0.0014895605854690075, -0.006349347531795502, -0.025820691138505936, -0.027371836826205254, 0.12268994748592377, -0.007792455609887838, -0.038522735238075256, 0.014383506961166859, -0.09218427538871765, 0.008695696480572224, 0.0026133626233786345, 0.09103470295667648, -0.030313586816191673, -0.09604638814926147, 0.022289127111434937, -0.09024307876825333, -0.0329473577439785, 0.0715833455324173, -0.008893114514648914, -0.025708947330713272, -0.0791395828127861, 0.014530394226312637, -0.07420426607131958, 0.08045009523630142, 0.07804080843925476, -0.012957049533724785, 0.019897079095244408, 0.011450347490608692, 0.051634203642606735, -0.12571601569652557, 0.011675059795379639, -0.0463065505027771, 0.0033813512418419123, 0.005173458252102137, 0.02818421460688114, 0.023271556943655014, 0.0040886071510612965, 0.008011856116354465, -0.017078526318073273, 0.0794496014714241, -0.05466398224234581, 0.025513894855976105, 0.03381356596946716, 0.09233348071575165, 0.022148793563246727, -0.01819870062172413, 0.0032429592683911324, -0.040027961134910583, -0.038080208003520966, 0.0524541474878788, 0.06670206785202026, -0.026317626237869263, 0.02363463118672371, 0.06188132241368294, -0.026366015896201134, 0.0406007319688797, -0.038859494030475616, 0.1213383823633194, -0.043544989079236984, -0.011664147488772869, -0.015057694166898727, -0.039729513227939606, 0.06364050507545471, 0.00462158489972353, 0.007112844847142696, 0.019478226080536842, 0.004021980334073305, 0.04912211000919342, 0.05309614539146423, -0.034766968339681625, -0.057222455739974976, 0.06325113028287888, 0.0004573156766127795, 0.03859064728021622, 0.07343202084302902, -0.026295578107237816, -0.11324035376310349, -0.06495117396116257, 0.20607662200927734, -0.03626525029540062, 0.029907524585723877, -0.05536345764994621, 0.008767390623688698, -0.02121806889772415, 0.008762259036302567, 0.028472937643527985, -0.03460258990526199, 0.049797095358371735, -0.01885395683348179, -0.043652839958667755, -0.025585724040865898, 0.017332684248685837, -0.011129260063171387, 0.032766833901405334, 0.03506525605916977, 0.054944075644016266, 0.10390882194042206, 0.04061216861009598, 0.021712468937039375, -0.024425383657217026, -0.005160620901733637, -0.00934190209954977, 0.10581017285585403, 0.04529662802815437, -0.036636512726545334, -0.04464993625879288, -5.2400915337887305e-33, -0.04903077706694603, -0.04560505971312523, 0.06606083363294601, 0.0015987660735845566, 0.02337028831243515, -0.033940389752388, -0.0207201037555933, -0.02059018239378929, -0.03648066520690918, -0.01039306540042162, -0.10783454030752182, 0.016802098602056503, -0.07954592257738113, 0.04248006269335747, 0.13682296872138977, 0.01094120368361473, 0.008169974200427532, 0.030376257374882698, -0.06491053104400635, -0.007083691190928221, 0.028803128749132156, -0.0353609137237072, 0.0006857757107354701, -0.00470335828140378, -0.024086305871605873, 0.01617317833006382, 0.02467925287783146, -0.04610143229365349, 0.0454576276242733, 0.0008296489249914885, -0.0030555042903870344, 0.07388892024755478, -0.054778918623924255, 0.006398477591574192, -0.010182938538491726, -0.013622491620481014, -0.02577156201004982, -0.018861856311559677, 0.01854054071009159, 0.07305708527565002, -0.03451256453990936, 0.025277789682149887, 0.00011172803351655602, 0.01005211565643549, -0.01425936259329319, -0.001591733773238957, 0.04002229869365692, -0.007197401951998472, -0.014384244568645954, -0.013920888304710388, -0.0356358103454113, 0.03647307679057121, 0.008935696445405483, -0.05683503299951553, 0.0535946860909462, -0.006161457393318415, -0.021721474826335907, 0.03370985761284828, -0.02362598478794098, -0.020359979942440987, 0.030925080180168152, 0.07569505274295807, -0.022979293018579483, 0.11616440117359161, -0.013501150533556938, 0.04918878525495529, 0.010986263863742352, 0.02795197255909443, 0.12113883346319199, 0.016506439074873924, -0.050924431532621384, -0.02870364859700203, 0.039391033351421356, 0.005959338508546352, -0.06095835939049721, 0.00887211598455906, -0.014630445279181004, -0.0711837187409401, -0.0076596857979893684, -0.0735979825258255, -0.11550982296466827, -0.013440488837659359, -0.04058428481221199, 0.00040526321390643716, 0.037432920187711716, -0.03617323189973831, -0.02640652470290661, -0.038517359644174576, 0.01877937838435173, -0.010150988586246967, -0.08086314052343369, 0.011855191551148891, -0.022952023893594742, 0.05883048102259636, -0.07994718849658966, 4.6267957233464336e-33, -0.07962001860141754, -0.03951388597488403, -0.06382595002651215, 0.08893603831529617, -0.003736267564818263, -0.016144176945090294, -0.017867151647806168, -0.042514584958553314, 0.02442728914320469, 0.06664492934942245, -0.0578959695994854, -0.04232950136065483, 0.013483372516930103, 0.04562925174832344, 0.006878789979964495, -0.006714722141623497, 0.014821702614426613, -0.03707454726099968, -0.008778832852840424, 0.027316149324178696, -0.023431498557329178, 0.022865207865834236, -0.03276344761252403, -0.06674011796712875, -0.015621465630829334, 0.09837546944618225, -0.02256227284669876, 0.055789873003959656, -0.02722344920039177, 0.02365402691066265, 0.025091223418712616, -0.05378679558634758, -0.04549097269773483, 0.03996357321739197, 0.010178114287555218, 0.09332837909460068, 0.05655767768621445, -0.05569127947092056, -0.04962647706270218, 0.0039370390586555, 0.05255492404103279, -0.03237328678369522, -0.05560147389769554, 0.09626688063144684, -0.03771008551120758, -0.001854786998592317, -0.040988121181726456, 0.09643056988716125, -0.0009849563939496875, -0.021389706060290337, -0.04590708762407303, 0.016152795404195786, -0.059220120310783386, -0.08145695179700851, -0.10162121802568436, 0.0024455301463603973, -0.014739158563315868, 0.014749233610928059, 0.007728506810963154, 0.046453021466732025, -0.012513810768723488, -0.006437175441533327, -0.0182336438447237, 0.042206428945064545, -0.08553381264209747, 0.04589935019612312, 0.021831268444657326, 0.03515465930104256, 0.001575260073877871, -0.03905196860432625, 0.13990843296051025, 0.018116934224963188, -0.027118152007460594, 0.07361293584108353, -0.035381462424993515, 0.0038903055246919394, -0.09528201818466187, 0.00967747438699007, -0.004546604584902525, -0.059779681265354156, -0.055846989154815674, -0.08561261743307114, -0.0061438255943357944, 0.0746932104229927, -0.028714386746287346, 0.08817903697490692, 0.012425371445715427, -0.03300650417804718, -0.028493493795394897, 0.02821928821504116, -0.0009966091020032763, 0.04937565326690674, 0.0024041649885475636, 0.0009695966728031635, -0.13609416782855988, -1.2270175986373033e-08, -0.015120251104235649, -0.01851866953074932, 0.10543894022703171, 0.006514150649309158, 0.06480390578508377, 0.022934259846806526, -0.06322948634624481, 0.005378672853112221, -0.011222971603274345, -0.026959313079714775, -0.005579785909503698, -0.020429058000445366, 0.08938048034906387, 0.03170343488454819, 0.07528702914714813, -0.00371625367552042, -0.025884391739964485, 0.021603476256132126, -0.008521676994860172, -0.0044897617772221565, 0.10893258452415466, -0.0013882535276934505, -0.04064278304576874, 0.008054762147367, 0.012936683371663094, -0.06289545446634293, -0.003492689924314618, 0.03347351402044296, -0.049912724643945694, 0.11565358936786652, -0.003106937278062105, 0.10181652754545212, 0.050687503069639206, -0.009205169975757599, 0.06699427962303162, 0.056775741279125214, 0.013960299082100391, -0.047010380774736404, -0.04209922254085541, -0.02042972669005394, -0.01677839830517769, 0.09026879072189331, 0.00997864454984665, -0.08400093019008636, 0.10684650391340256, 0.004483711440116167, -0.006322822999209166, -0.13133105635643005, 0.07453566789627075, -0.05268343538045883, -0.011863199062645435, 0.0022888989187777042, 0.038244668394327164, 0.12563945353031158, 0.11970926821231842, -0.00972486287355423, 0.01195052545517683, -0.033788952976465225, -0.03487560153007507, 0.08929373323917389, 0.1176525130867958, 0.049785468727350235, 0.04860148951411247, -0.062488894909620285]\n"
     ]
    }
   ],
   "source": [
    "texts=[\"AI\",\"MAchine learning\",\"Deep Learning\",\"Neural Network\"]\n",
    "batch_embeddings=embeddings.embed_documents(texts)\n",
    "print(batch_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce23d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.024391867220401764, 0.003244456136599183, 0.05426763743162155, -0.006672606337815523, 0.003935696557164192, -0.007957395166158676, 0.025025220587849617, -0.03203269839286804, -0.05451072007417679, -0.04470203444361687, -0.013759402558207512, 0.01606130041182041, 0.04036473482847214, -0.020260972902178764, -0.06097458675503731, 0.02065557986497879, 0.010556355118751526, -0.01626480743288994, -0.10490719974040985, -0.11068311333656311, -0.02154473029077053, -0.013036100193858147, -0.0868835523724556, 0.02715190500020981, 0.02614404819905758, 0.039646562188863754, 0.06494351476430893, 0.06547264009714127, 0.017963264137506485, -0.10655661672353745, 0.009878220967948437, -0.03496198356151581, 0.03040350414812565, 0.014532740227878094, -0.11560278385877609, 0.012346209026873112, -0.06430960446596146, 0.043945975601673126, 0.019033126533031464, 0.030984828248620033, -0.015413882210850716, -0.08163449913263321, 0.012414454482495785, 0.0124236810952425, 0.06950362026691437, 0.07782552391290665, -0.003623021999374032, -0.012933319434523582, -0.03990821912884712, 0.04830602556467056, -0.09634711593389511, -0.01489766500890255, -0.03323810175061226, -0.01872231811285019, -0.06525664031505585, 0.03418881818652153, 0.015635045245289803, -0.01761299930512905, 0.0451909638941288, -0.0033851878251880407, 0.05846897512674332, -0.08247904479503632, -0.08394180238246918, 0.009083970449864864, 0.11585061997175217, 0.007994645275175571, -0.007061502896249294, 0.06556668877601624, -0.04982605576515198, -0.06344431638717651, -0.03080604039132595, 0.035419661551713943, -0.03202145919203758, 0.04848293215036392, 0.06485562771558762, -0.02143753133714199, 0.0386873222887516, 0.034611959010362625, 0.08124355971813202, -0.027631597593426704, -0.057965729385614395, -0.0053001511842012405, -0.03869609162211418, 0.06329432129859924, 0.0542885959148407, -0.013839224353432655, -0.03217104822397232, 0.025089716538786888, -0.026432553306221962, -0.012826988473534584, -0.01823442243039608, -0.017002616077661514, 0.048660799860954285, -0.05585093051195145, -0.08782372623682022, 0.06937868893146515, 0.0017593040829524398, -0.1565755158662796, 0.025016997009515762, 0.2359813004732132, -0.0573931448161602, 0.03341680392622948, 0.004063519183546305, 0.002972256625071168, 0.012201801873743534, -0.05714806169271469, 0.008463190868496895, -0.000880196806974709, 0.09577091783285141, -0.1116890162229538, -0.06799854338169098, -0.01838214509189129, -0.0019815252162516117, -0.05596805363893509, 0.037770532071590424, -0.03700875863432884, 0.027574285864830017, -0.013179486617445946, -0.023938320577144623, 0.03731609135866165, -0.044179197400808334, -0.031971752643585205, 0.0034277294762432575, 0.07126104831695557, -0.028087377548217773, -0.06719310581684113, -0.06107553467154503, 3.4693854806743335e-34, -0.005817217752337456, -0.08467630296945572, -0.029431432485580444, 0.02706746757030487, 0.017203347757458687, -0.094223253428936, 0.005866233259439468, -0.06413035094738007, 0.04407786205410957, 0.020572882145643234, -0.041366368532180786, 0.007860342971980572, 0.025641659274697304, -0.023032598197460175, 0.12271451205015182, -0.0032399334013462067, 0.03975469619035721, 0.11409460008144379, -0.028409985825419426, -0.023189041763544083, -0.01807643286883831, -0.02377227321267128, 0.06041113659739494, 0.003028744598850608, -0.02775662951171398, 0.0221165232360363, 0.021916424855589867, 0.03116009198129177, -0.037669215351343155, 0.029563376680016518, 0.06582334637641907, 0.02049536630511284, -0.027424849569797516, 0.006949566304683685, 0.05936913192272186, -0.010037519037723541, 0.005115823354572058, 0.030645081773400307, 0.06478003412485123, -0.013958345167338848, -0.07033710181713104, -0.06081150844693184, 0.07511110603809357, -0.012875516898930073, -0.023970915004611015, 0.0456763356924057, 0.029919957742094994, -0.06532848626375198, -0.04985169693827629, 0.009194494225084782, 0.01549928542226553, -0.024661293253302574, -0.04430849850177765, 0.026672670617699623, 0.03257698938250542, 0.1142728254199028, -0.029759449884295464, -0.003366312477737665, -0.012980680912733078, -0.03371136263012886, 0.09232019633054733, 0.03177569806575775, 0.011751607060432434, 0.02885225974023342, -0.0328315831720829, 0.006203959695994854, 0.027960719540715218, -0.013924279250204563, 0.023418530821800232, 0.01748502254486084, -0.010036963038146496, -0.0031003302428871393, 0.061211541295051575, -0.05625144764780998, 0.03688796982169151, 0.04328001290559769, 0.02567940205335617, 0.05452920123934746, -0.05457068234682083, -0.004109239671379328, -0.13821332156658173, -0.01706111617386341, 0.0039464435540139675, -0.04147116094827652, 0.0038360261823982, -0.05676253139972687, 0.022154999896883965, -0.045444339513778687, -0.03093511052429676, 0.052334532141685486, -0.11291734874248505, 0.06874141842126846, 0.047811511904001236, 0.03641745075583458, -0.05786075443029404, -8.327929318354656e-34, -0.13148146867752075, 0.0359136126935482, 0.0636676549911499, 0.11079362034797668, 0.02291910909116268, 0.020604772493243217, -0.04067500680685043, -0.04038142040371895, 0.00542123056948185, 0.0888499915599823, -0.012691144831478596, 0.026951931416988373, 0.060831695795059204, -0.00026342092314735055, -0.08807061612606049, 0.07137762755155563, 0.007459018845111132, -0.029905403032898903, -0.006546348333358765, 0.07382956892251968, -0.040294088423252106, 0.05264332517981529, -0.022477995604276657, -0.014469118788838387, -0.0043293796479702, 0.004191339481621981, -0.018816476687788963, 0.015351889654994011, -0.055843885987997055, -0.04658326879143715, -0.015183299779891968, -0.038673192262649536, -0.04416891932487488, 0.05372648313641548, -0.058505184948444366, 0.03006470389664173, -0.0024193371646106243, 0.019356369972229004, 0.0057325949892401695, 0.10568244755268097, 0.036508768796920776, 0.05105724185705185, -0.10807371884584427, 0.03211064636707306, -0.029158171266317368, -0.10622184723615646, -0.06207778677344322, 0.022346414625644684, 0.06606439501047134, -0.0397040918469429, -0.03218122199177742, 0.05124161019921303, -0.015171577222645283, -0.06061477214097977, -0.0211336612701416, 0.027605490759015083, -0.028027618303894997, -0.03876348212361336, 0.021921446546912193, 0.05509587749838829, -0.13183659315109253, -0.05344819277524948, 0.015805015340447426, 0.08465725183486938, 0.006558401044458151, -0.016120798885822296, -0.028955111280083656, 0.04573336988687515, -0.03544670343399048, 0.01591772772371769, 0.07113132625818253, 0.060121480375528336, -0.012370951473712921, 0.011201562359929085, -0.01618112064898014, -0.04245225712656975, -0.0784253180027008, -0.03906384855508804, -0.03729783743619919, -0.04025382921099663, 0.03067474626004696, -0.05714094266295433, 0.02939578890800476, 0.0831070989370346, 0.019608110189437866, 0.05521954223513603, 0.09535326808691025, -0.014108908362686634, 0.03366796299815178, -0.05669642984867096, -0.012401491403579712, 0.037359170615673065, -0.0032964691054075956, 0.01161139365285635, -0.054700370877981186, -1.4752099986026224e-08, -0.027424786239862442, -0.07633446902036667, 0.08716373890638351, -0.002467499813064933, 0.050779324024915695, 0.04894994571805, -0.06277704983949661, 0.08619402348995209, -0.028905345126986504, 0.006605556700378656, 0.033771540969610214, 0.020471682772040367, -0.02795041911303997, 0.06820955872535706, -0.015135416761040688, 0.007914453744888306, -0.022510413080453873, 0.06165093556046486, -0.02477976866066456, 0.013340081088244915, 0.08776803314685822, 0.06991861760616302, 0.046172935515642166, 0.010393432341516018, 0.10544240474700928, -0.05000016838312149, 0.01867707446217537, 0.06655577570199966, 0.021773092448711395, 0.062181707471609116, -0.031199272722005844, 0.09787549078464508, 0.026895513758063316, -0.018385065719485283, 0.10476375371217728, 0.08063991367816925, 0.00943601131439209, -0.07085253298282623, -0.02575552836060524, 0.041329652070999146, -0.02937311865389347, 0.03996399790048599, -0.08191832154989243, -0.028407089412212372, 0.025465400889515877, 0.017960725352168083, 0.04338834062218666, -0.1254221796989441, 0.029067549854516983, -0.004652774427086115, 0.041268087923526764, 0.04118117317557335, 0.04932033643126488, 0.032355163246393204, 0.018704283982515335, 0.05770042538642883, 0.05088115110993385, -0.03482009097933769, -0.0009678634232841432, 0.022411929443478584, 0.040253207087516785, 0.035362739115953445, -0.021799158304929733, -0.05384536460042]\n"
     ]
    }
   ],
   "source": [
    "print(batch_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4452d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare Embedding using cosine similarity\n",
    "\n",
    "def compare_embeddings(text1:str,text2:str):\n",
    "    \"\"\"Compare semantic simialrity of 2 texts usign embeddings\"\"\"\n",
    "\n",
    "    emb1=np.array(embeddings.embed_query(text1))\n",
    "    emb2=np.array(embeddings.embed_query(text2))\n",
    "\n",
    "    ## Calculate the simialrity score\n",
    "\n",
    "    similarity=np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19d2e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Similarity Examples:\n",
      "'AI' vs 'Artificial Intelligence': 0.791\n"
     ]
    }
   ],
   "source": [
    "# Test semantic similarity\n",
    "print(\"\\nSemantic Similarity Examples:\")\n",
    "print(f\"'AI' vs 'Artificial Intelligence': {compare_embeddings('AI', 'Artificial Intelligence'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ea6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AI' vs 'Pizza': 0.257\n"
     ]
    }
   ],
   "source": [
    "print(f\"'AI' vs 'Pizza': {compare_embeddings('AI', 'Pizza'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50296f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Machine Learning' vs 'ML': 0.373\n"
     ]
    }
   ],
   "source": [
    "print(f\"'Machine Learning' vs 'ML': {compare_embeddings('Machine Learning', 'ML'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9735ac2",
   "metadata": {},
   "source": [
    "### Create FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0989a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 4 vectors\n"
     ]
    }
   ],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "print(f\"Vector store created with {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32d15527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2360527f4d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0d43809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved to 'faiss_index' directory\n"
     ]
    }
   ],
   "source": [
    "## Save vector tore for later use\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"Vector store saved to 'faiss_index' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd954a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vector store contains 4 vectors\n"
     ]
    }
   ],
   "source": [
    "## load vector store\n",
    "loaded_vectorstore=FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded vector store contains {loaded_vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca90941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='26f45736-33d8-4f99-9d60-0b7a411c5824', metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.'), Document(id='1dc8c4cb-ad22-4f87-b7f9-3017e5420146', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.'), Document(id='8b168588-b2c7-4849-a95a-3b9486f118ef', metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.')]\n"
     ]
    }
   ],
   "source": [
    "## Similarity Search \n",
    "query=\"What is deep learning\"\n",
    "\n",
    "results=vectorstore.similarity_search(query,k=3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b21fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is deep learning\n",
      "\n",
      "Top 3 similar chunks:\n",
      "\n",
      "1. Source: Deep Learning\n",
      "   Content: Deep Learning is a subset of machine learning based on artificial neural networks.\n",
      "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
      "        Deep learning ...\n",
      "\n",
      "2. Source: ML Basics\n",
      "   Content: Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised...\n",
      "\n",
      "3. Source: NLP Overview\n",
      "   Content: Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
      "        It combines computational linguistics with machine learning and deep learning models.\n",
      "      ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 3 similar chunks:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Content: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0234314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Similarity search with scores:\n",
      "\n",
      "Score: 0.343\n",
      "Source: Deep Learning\n",
      "Content preview: Deep Learning is a subset of machine learning based on artificial neural networks.\n",
      "        It uses m...\n",
      "\n",
      "Score: 1.090\n",
      "Source: ML Basics\n",
      "Content preview: Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being...\n",
      "\n",
      "Score: 1.154\n",
      "Source: NLP Overview\n",
      "Content preview: Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "### Similarity Search with score\n",
    "results_with_scores=vectorstore.similarity_search_with_score(query,k=3)\n",
    "\n",
    "print(\"\\n\\nSimilarity search with scores:\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"\\nScore: {score:.3f}\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content preview: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a80f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.'),\n",
       " Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.'),\n",
       " Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46e0d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='1dc8c4cb-ad22-4f87-b7f9-3017e5420146', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.')]\n"
     ]
    }
   ],
   "source": [
    "### Search with metadata filtering\n",
    "filter_dict={\"topic\":\"ML\"}\n",
    "filtered_results=vectorstore.similarity_search(\n",
    "    query,\n",
    "    k=3,\n",
    "    filter=filter_dict\n",
    ")\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f153009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3214a1d",
   "metadata": {},
   "source": [
    "### Build RAG Chain With LCEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d6de908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B1F90CB360>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B1F90C8FC0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM GROQ LLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(model=\"groq:gemma2-9b-it\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c28e9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! \\n\\nHow can I help you today? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 10, 'total_tokens': 25, 'completion_time': 0.027272727, 'prompt_time': 0.00117063, 'queue_time': 0.253079486, 'total_time': 0.028443357}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--208de7c5-1ae3-45a8-a674-9e8c14783105-0', usage_metadata={'input_tokens': 10, 'output_tokens': 15, 'total_tokens': 25})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26844d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple RAG Chain with LCEL\n",
    "simple_prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the following context:\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f83433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic retriever\n",
    "retriever=vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d35a9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B1FA6E0D60>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# Format documents for the prompt\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    \"\"\"Format documents for insertion into prompt\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        formatted.append(f\"Document {i+1} (Source: {source}):\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c6f65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rag_chain=(\n",
    "    {\"context\":retriever | format_docs,\"question\":RunnablePassthrough() }\n",
    "    | simple_prompt\n",
    "    | llm\n",
    "    |StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c470a6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B1FA6E0D60>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B1F90CB360>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B1F90C8FC0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18098855",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conversational RAg Chain\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Use the provided context to answer questions.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c42689e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversational_rag():\n",
    "    \"\"\"Create a conversational RAG chain with memory\"\"\"\n",
    "    return (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x: format_docs(retriever.invoke(x[\"input\"]))\n",
    "        )\n",
    "        | conversational_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "conversational_rag = create_conversational_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f255f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: format_docs(retriever.invoke(x['input'])))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B1B03A3240>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Use the provided context to answer questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Context: {context}\\n\\nQuestion: {input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B1F90CB360>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B1F90C8FC0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c88574dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern RAG chains created successfully!\n",
      "Available chains:\n",
      "- simple_rag_chain: Basic Q&A\n",
      "- conversational_rag: Maintains conversation history\n",
      "- streaming_rag_chain: Supports token streaming\n"
     ]
    }
   ],
   "source": [
    "### streaming RAG chain\n",
    "streaming_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | simple_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "print(\"Modern RAG chains created successfully!\")\n",
    "print(\"Available chains:\")\n",
    "print(\"- simple_rag_chain: Basic Q&A\")\n",
    "print(\"- conversational_rag: Maintains conversation history\")\n",
    "print(\"- streaming_rag_chain: Supports token streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d8a26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function for different chain types\n",
    "def test_rag_chains(question: str):\n",
    "    \"\"\"Test all RAG chain variants\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Simple RAG\n",
    "    print(\"\\n1. Simple RAG Chain:\")\n",
    "    answer = simple_rag_chain.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    print(\"\\n2. Streaming RAG:\")\n",
    "    print(\"Answer: \", end=\"\", flush=True)\n",
    "    for chunk in streaming_rag_chain.stream(question):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5a9cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between AI and machine learning\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: AI is the broader concept of machines performing tasks that typically require human intelligence. Machine learning is a specific subset of AI where systems learn from data instead of being explicitly programmed.  \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: AI is the broad concept of machines simulating human intelligence, while machine learning is a subset of AI that allows systems to learn from data without explicit programming. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_rag_chains(\"What is the difference between AI and machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e375d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is the difference between AI and Machine Learning?\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: AI is the broader concept of machines performing tasks that typically require human intelligence, while Machine Learning is a specific subset of AI that allows systems to learn from data without explicit programming.  \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: Artificial Intelligence (AI) is the broad concept of machines simulating human intelligence, while Machine Learning (ML) is a subset of AI that focuses on enabling systems to learn from data without explicit programming.  \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: Explain deep learning in simple terms\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: Deep learning is a type of machine learning that uses artificial networks with many layers to learn from data.  Think of it like teaching a computer to recognize patterns, like pictures or words, by showing it lots of examples. Each layer in the network helps it learn more complex features, ultimately allowing it to make accurate predictions. \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: Deep learning is a type of machine learning that uses many layers of artificial neurons to learn complex patterns from data.  It's like teaching a computer to see and understand things the way humans do, by showing it lots of examples.  Deep learning has been especially successful in areas like computer vision (recognizing objects in images), natural language processing (understanding and generating text), and speech recognition. \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: How does NLP work?\n",
      "================================================================================\n",
      "\n",
      "1. Simple RAG Chain:\n",
      "Answer: NLP combines computational linguistics with machine learning and deep learning models.  \n",
      "\n",
      "\n",
      "2. Streaming RAG:\n",
      "Answer: NLP combines computational linguistics with machine learning and deep learning models.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple questions\n",
    "test_questions = [\n",
    "    \"What is the difference between AI and Machine Learning?\",\n",
    "    \"Explain deep learning in simple terms\",\n",
    "    \"How does NLP work?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    test_rag_chains(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "afcfe3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Conversational RAG Example:\n",
      "Q1: What is machine learning?\n",
      "A1: Machine learning is a subset of artificial intelligence that allows systems to learn from data instead of being explicitly programmed. \n",
      "\n",
      "ML algorithms identify patterns in data to make predictions or decisions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Conversational example\n",
    "print(\"\\n3. Conversational RAG Example:\")\n",
    "chat_history = []\n",
    "\n",
    "# First question\n",
    "q1 = \"What is machine learning?\"\n",
    "a1 = conversational_rag.invoke({\n",
    "    \"input\": q1,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "\n",
    "print(f\"Q1: {q1}\")\n",
    "print(f\"A1: {a1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3a72dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update history\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=q1),\n",
    "    AIMessage(content=a1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b9eda39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2: How is it different from traditional programming?\n",
      "A2: Here's how machine learning differs from traditional programming, drawing from the provided context:\n",
      "\n",
      "**Traditional Programming:**\n",
      "\n",
      "* **Explicit Instructions:**  Programmers write very specific instructions (code) that the computer follows step-by-step.  \n",
      "* **Rule-Based:**  Programs rely on predefined rules and logic to process information.\n",
      "\n",
      "**Machine Learning:**\n",
      "\n",
      "* **Learning from Data:** Instead of explicit rules, ML algorithms learn patterns and relationships from large datasets.\n",
      "* **Data-Driven:** The \"program\" is not fixed code but a set of algorithms that adapt and improve based on the data they are trained on.\n",
      "\n",
      "**In essence:**\n",
      "\n",
      "Traditional programming is like giving the computer a detailed recipe to follow. Machine learning is more like giving the computer a bunch of ingredients and letting it figure out how to make something delicious based on patterns it observes. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question\n",
    "q2 = \"How is it different from traditional programming?\"\n",
    "a2 = conversational_rag.invoke({\n",
    "    \"input\": q2,\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "print(f\"\\nQ2: {q2}\")\n",
    "print(f\"A2: {a2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ada94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Udemy Krish Naik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
